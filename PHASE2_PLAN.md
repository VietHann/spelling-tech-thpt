# Phase 2 Implementation Plan

## ğŸ¯ Má»¥c tiÃªu

Implement **Candidate Generator** vÃ  **Noisy-Channel Ranker** Ä‘á»ƒ hoÃ n thiá»‡n pipeline sá»­a lá»—i.

Hiá»‡n táº¡i Phase 1 chá»‰ **detect** lá»—i, Phase 2 sáº½ **generate candidates** vÃ  **rank** Ä‘á»ƒ chá»n correction tá»‘t nháº¥t.

---

## ğŸ“‹ Tasks

### 2.1 Candidate Generator

#### A. SymSpell
- [ ] Implement SymSpell algorithm (edit distance 1-2)
- [ ] Build SymSpell dictionary tá»« lexicon
- [ ] Support cáº£ cÃ³ dáº¥u vÃ  khÃ´ng dáº¥u
- [ ] Optimize vá»›i prefix tree

**Files:**
- `candidate_generator.py` â†’ `SymSpellGenerator`

**Data needed:**
- Lexicon vá»›i frequency counts
- Toneless â†’ toned mapping

#### B. Telex/VNI Converter
- [ ] Build Telex conversion rules (sâ†’Å›, fâ†’Ì€, aaâ†’Ã¢, uwâ†’Æ°, ddâ†’Ä‘)
- [ ] Build VNI conversion rules (1â†’Ì, 2â†’Ì€, 3â†’Ì‰, 4â†’Ìƒ, 5â†’Ì£)
- [ ] Reverse conversion (detect Telex/VNI patterns)
- [ ] Generate candidates by applying rules

**Files:**
- `candidate_generator.py` â†’ `TelexVNIGenerator`

**Data needed:**
- Telex/VNI mapping tables
- Common error patterns

#### C. Keyboard Adjacency
- [ ] Build Vietnamese keyboard layout map (QWERTY)
- [ ] Generate candidates by swapping adjacent keys
- [ ] Support Damerau-Levenshtein (swap, insert, delete, replace)

**Files:**
- `candidate_generator.py` â†’ `KeyboardGenerator`

**Data needed:**
- Keyboard layout map (qâ†”w, aâ†”s, etc.)

#### D. Split/Join
- [ ] Detect merged words ("Ä‘á»ƒlÃ m" â†’ "Ä‘á»ƒ lÃ m")
- [ ] Detect split words ("Ä‘á»ƒ lÃ m" â†’ "Ä‘á»ƒlÃ m")
- [ ] Use lexicon to validate splits

**Files:**
- `candidate_generator.py` â†’ `SplitJoinGenerator`

#### E. Toneless â†’ Toned
- [ ] Build mapping tá»« khÃ´ng dáº¥u â†’ cÃ³ dáº¥u
- [ ] Handle ambiguous cases (e.g., "viet" â†’ "viá»‡t", "viáº¿t", "viÃªt")
- [ ] Use frequency to rank

**Files:**
- `candidate_generator.py` â†’ `DiacriticRestorer`

**Data needed:**
- Toneless â†’ toned mapping with frequencies

---

### 2.2 Noisy-Channel Ranker

#### A. Feature Extractors

**Features:**
1. **LM_masked**: Masked-LM score (PhoBERT)
2. **LM_5gram**: 5-gram LM score (KenLM)
3. **P_err**: Error model probability
   - Telex/VNI probability
   - Keyboard adjacency probability
   - Edit operation probability
4. **freq**: Unigram frequency
5. **edit_dist**: Edit distance from observed
6. **ortho**: Orthography bonus (valid Vietnamese syllable structure)

**Files:**
- `ranker.py` â†’ `FeatureExtractor`

#### B. Scoring Function

```python
score(c) = Î»1*LM_masked(c, ctx) 
         + Î»2*LM_5gram(c, ctx)
         + Î»3*log(P_err(observed | c))
         + Î»4*log(freq(c))
         - Î»5*edit_dist(observed, c)
         + Î»6*ortho_bonus(c)
```

**Files:**
- `ranker.py` â†’ `NoisyChannelRanker`

#### C. Weight Tuning
- [ ] Implement grid search on dev set
- [ ] Optimize weights (Î»1, Î»2, ..., Î»6)
- [ ] Save best weights to config

**Files:**
- `tune_ranker.py`

---

### 2.3 Data Preparation

#### A. KenLM 5-gram
- [ ] Download Vietnamese corpus (Wikipedia, news)
- [ ] Clean and tokenize corpus
- [ ] Train KenLM 5-gram model
- [ ] Prune model for speed

**Commands:**
```bash
# Install KenLM
git clone https://github.com/kpu/kenlm.git
cd kenlm
mkdir build && cd build
cmake .. && make -j4

# Train model
./bin/lmplz -o 5 < corpus.txt > vi_5gram.arpa
./bin/build_binary vi_5gram.arpa vi_5gram.bin
```

**Files:**
- `data/vi_5gram.bin`

#### B. Frequency Dictionary
- [ ] Extract unigram/bigram frequencies from corpus
- [ ] Save to JSON

**Files:**
- `data/vi_freq.json`

**Format:**
```json
{
  "tÃ´i": 123456,
  "lÃ ": 98765,
  "cÃ³": 87654,
  ...
}
```

#### C. Toneless â†’ Toned Mapping
- [ ] Build mapping from lexicon
- [ ] Handle ambiguous cases with frequencies

**Files:**
- `data/toneless_to_toned.json`

**Format:**
```json
{
  "viet": [
    {"word": "viá»‡t", "freq": 10000},
    {"word": "viáº¿t", "freq": 5000}
  ],
  ...
}
```

#### D. Error Patterns
- [ ] Collect Telex/VNI error patterns
- [ ] Collect keyboard adjacency patterns
- [ ] Estimate P_err from corpus

**Files:**
- `data/error_patterns.json`

---

## ğŸ”§ Implementation Order

### Week 1: Candidate Generator
1. **Day 1-2**: SymSpell
   - Implement algorithm
   - Build dictionary
   - Test on sample data

2. **Day 3-4**: Telex/VNI
   - Build conversion rules
   - Implement reverse detection
   - Test on common errors

3. **Day 5**: Keyboard + Split/Join
   - Keyboard adjacency map
   - Split/join logic
   - Integration test

### Week 2: Ranker + Data
1. **Day 1-2**: Feature Extractors
   - Implement all 6 features
   - Test individually

2. **Day 3-4**: Noisy-Channel Ranker
   - Implement scoring function
   - Initial weights (manual tuning)
   - Integration with generator

3. **Day 5**: Data Preparation
   - Train KenLM
   - Build frequency dict
   - Build mappings

### Week 3: Integration + Tuning
1. **Day 1-2**: End-to-end integration
   - Update `AdvancedCorrector`
   - Update API endpoint
   - Test full pipeline

2. **Day 3-4**: Weight Tuning
   - Grid search on dev set
   - Optimize weights
   - Evaluate on test set

3. **Day 5**: Documentation + Testing
   - Update README
   - Write tests
   - Performance benchmarks

---

## ğŸ“Š Expected Results

### Before Phase 2 (Current)
```
Input:  "TÃ´ii Ä‘angg há»cc tiáº¿ng Viá»‡t"
Output: {
  "detections": [
    {"position": 0, "token": "TÃ´ii", "confidence": 0.85},
    {"position": 1, "token": "Ä‘angg", "confidence": 0.82},
    {"position": 2, "token": "há»cc", "confidence": 0.79}
  ],
  "corrections": [],  # Empty!
  "final": "TÃ´ii Ä‘angg há»cc tiáº¿ng Viá»‡t"  # No change
}
```

### After Phase 2 (Expected)
```
Input:  "TÃ´ii Ä‘angg há»cc tiáº¿ng Viá»‡t"
Output: {
  "detections": [
    {"position": 0, "token": "TÃ´ii", "confidence": 0.85},
    {"position": 1, "token": "Ä‘angg", "confidence": 0.82},
    {"position": 2, "token": "há»cc", "confidence": 0.79}
  ],
  "corrections": [
    {"position": 0, "original": "TÃ´ii", "correction": "TÃ´i", "score": 0.95},
    {"position": 1, "original": "Ä‘angg", "correction": "Ä‘ang", "score": 0.93},
    {"position": 2, "original": "há»cc", "correction": "há»c", "score": 0.91}
  ],
  "final": "TÃ´i Ä‘ang há»c tiáº¿ng Viá»‡t"  # Corrected!
}
```

---

## ğŸ§ª Testing Strategy

### Unit Tests
- [ ] Test each generator individually
- [ ] Test feature extractors
- [ ] Test ranker scoring

### Integration Tests
- [ ] Test generator â†’ ranker pipeline
- [ ] Test full correction pipeline
- [ ] Test API endpoint

### Evaluation Metrics
- [ ] Exact Match (EM)
- [ ] Normalized Edit Distance (NED)
- [ ] Precision/Recall/F1 for detection
- [ ] Correction accuracy

### Benchmark Dataset
- Use VSEC test set
- Compare with v1 (original corrector)
- Target: EM > 0.7, NED < 0.1

---

## ğŸ“¦ Dependencies

### Python packages
```bash
pip install symspellpy  # SymSpell
pip install kenlm       # KenLM Python bindings
```

### External tools
- KenLM (for training 5-gram model)
- Vietnamese corpus (Wikipedia dump)

---

## ğŸš€ Quick Start (After Phase 2)

```python
from advanced_corrector import AdvancedCorrector

corrector = AdvancedCorrector(
    detector_dir="outputs/detector",
    lexicon_path="data/vi_lexicon.txt",
    kenlm_path="data/vi_5gram.bin",
    freq_dict_path="data/vi_freq.json",
)

result = corrector.correct("TÃ´ii Ä‘angg há»cc tiáº¿ng Viá»‡t")
print(result['final'])  # "TÃ´i Ä‘ang há»c tiáº¿ng Viá»‡t"
```

---

## ğŸ“ Files to Create

### Phase 2 Files
```
T3_VietLe/
â”œâ”€â”€ candidate_generator.py      # NEW
â”‚   â”œâ”€â”€ SymSpellGenerator
â”‚   â”œâ”€â”€ TelexVNIGenerator
â”‚   â”œâ”€â”€ KeyboardGenerator
â”‚   â”œâ”€â”€ SplitJoinGenerator
â”‚   â””â”€â”€ DiacriticRestorer
â”œâ”€â”€ ranker.py                    # NEW
â”‚   â”œâ”€â”€ FeatureExtractor
â”‚   â””â”€â”€ NoisyChannelRanker
â”œâ”€â”€ tune_ranker.py               # NEW
â”œâ”€â”€ prepare_kenlm.py             # NEW
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ vi_5gram.bin             # NEW
â”‚   â”œâ”€â”€ vi_freq.json             # NEW
â”‚   â”œâ”€â”€ toneless_to_toned.json   # NEW
â”‚   â””â”€â”€ error_patterns.json      # NEW
â””â”€â”€ tests/
    â”œâ”€â”€ test_generator.py        # NEW
    â””â”€â”€ test_ranker.py           # NEW
```

---

## ğŸ¯ Success Criteria

Phase 2 is complete when:
- [x] All 5 generators implemented and tested
- [x] Noisy-channel ranker with 6 features
- [x] KenLM 5-gram trained and integrated
- [x] Frequency dict and mappings built
- [x] End-to-end correction works
- [x] EM > 0.7 on VSEC test set
- [x] API returns actual corrections (not empty)
- [x] Documentation updated
- [x] Tests pass

---
