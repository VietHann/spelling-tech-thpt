\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[vietnamese]{babel}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{url}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

% Code listing style
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red}
}

\title{Ứng dụng công nghệ số trong việc cải thiện lỗi chính tả của học sinh THPT}
\author{\IEEEauthorblockN{Lê Văn Việt, Đoàn Minh Châu}
\IEEEauthorblockA{Khoa Công Nghệ Thông Tin \\
Trường Đại Học Đại Nam \\
}}

\begin{document}
\maketitle

\begin{abstract}
Lỗi chính tả là một trong những vấn đề phổ biến ảnh hưởng đến chất lượng văn bản của học sinh trung học phổ thông (THPT). Bài báo này trình bày một hệ thống sửa lỗi chính tả tiếng Việt tự động sử dụng công nghệ học sâu và xử lý ngôn ngữ tự nhiên. Hệ thống được thiết kế theo kiến trúc đa tầng với ba thành phần chính: (1) tầng tiền xử lý với chuẩn hóa Unicode và tách từ, (2) tầng phát hiện lỗi sử dụng ensemble của ba bộ detector (OOV, Masked Language Model, và Token Classifier), và (3) tầng sửa lỗi với candidate generation và noisy-channel ranking. Kết quả thử nghiệm trên tập dữ liệu VSEC cho thấy hệ thống đạt độ chính xác phát hiện lỗi cao với F1-score 0.82 và khả năng xử lý realtime. Hệ thống đã được triển khai dưới dạng API web service và ứng dụng web, có thể được tích hợp vào các nền tảng học tập trực tuyến để hỗ trợ học sinh cải thiện kỹ năng viết.
\end{abstract}

\begin{IEEEkeywords}
Sửa lỗi chính tả, Xử lý ngôn ngữ tự nhiên, Học sâu, Tiếng Việt, THPT
\end{IEEEkeywords}

\section{Giới thiệu}

\subsection{Bối cảnh và động lực}
Trong bối cảnh chuyển đổi số giáo dục, việc ứng dụng công nghệ để hỗ trợ học sinh cải thiện kỹ năng viết đang trở nên cấp thiết. Theo khảo sát của Bộ Giáo dục và Đào tạo năm 2023, khoảng 65\% học sinh THPT mắc lỗi chính tả trong các bài kiểm tra văn bản, ảnh hưởng đến điểm số và khả năng diễn đạt ý tưởng.

Các lỗi chính tả phổ biến ở học sinh THPT bao gồm:
\begin{itemize}
    \item \textbf{Lỗi dấu thanh}: Nhầm lẫn giữa các dấu sắc, huyền, hỏi, ngã, nặng
    \item \textbf{Lỗi Telex/VNI}: Do gõ bàn phím không hoàn chỉnh (ví dụ: "tôii" thay vì "tôi")
    \item \textbf{Lỗi bàn phím}: Nhấn nhầm phím kề nhau (ví dụ: "đangg" thay vì "đang")
    \item \textbf{Lỗi ghép/tách từ}: Viết liền hoặc tách rời các từ (ví dụ: "đểlàm" thay vì "để làm")
    \item \textbf{Lỗi không dấu}: Quên đánh dấu thanh (ví dụ: "tieng Viet" thay vì "tiếng Việt")
\end{itemize}

\subsection{Mục tiêu nghiên cứu}
Nghiên cứu này nhằm xây dựng một hệ thống sửa lỗi chính tả tiếng Việt tự động với các mục tiêu sau:
\begin{enumerate}
    \item Phát hiện chính xác các lỗi chính tả phổ biến của học sinh THPT
    \item Đề xuất các sửa lỗi phù hợp với ngữ cảnh
    \item Xử lý realtime để tích hợp vào các ứng dụng học tập
    \item Cung cấp giải thích chi tiết về lỗi để học sinh hiểu và cải thiện
\end{enumerate}

\subsection{Đóng góp chính}
Các đóng góp chính của nghiên cứu bao gồm:
\begin{itemize}
    \item Kiến trúc đa tầng kết hợp nhiều phương pháp phát hiện và sửa lỗi
    \item Ensemble detector với ba chiến lược bổ trợ lẫn nhau
    \item Pipeline tiền xử lý bảo vệ các pattern đặc biệt (URL, email, code)
    \item API web service và ứng dụng web demo
    \item Mã nguồn mở và tài liệu chi tiết
\end{itemize}

\section{Công trình liên quan}

\subsection{Sửa lỗi chính tả tiếng Việt}
Các nghiên cứu trước đây về sửa lỗi chính tả tiếng Việt chủ yếu sử dụng các phương pháp dựa trên từ điển và luật \cite{nguyen2018vietnamese}. Gần đây, các phương pháp học sâu đã được áp dụng với kết quả khả quan \cite{tran2021deep}.

\subsection{Grammatical Error Correction (GEC)}
Các hệ thống GEC hiện đại sử dụng mô hình sequence-to-sequence như BART \cite{lewis2020bart} và T5 \cite{raffel2020t5}. Đối với tiếng Việt, BARTpho \cite{nguyen2022bartpho} và PhoBERT \cite{nguyen2020phobert} đã cho thấy hiệu quả cao.

\subsection{Noisy Channel Model}
Mô hình noisy channel \cite{kernighan1990spelling} kết hợp language model và error model để xếp hạng các candidate corrections. Nghiên cứu này mở rộng mô hình này với feature stack phong phú hơn.

\section{Phương pháp đề xuất}

\subsection{Tổng quan kiến trúc}
Hệ thống được thiết kế theo kiến trúc ba tầng như minh họa trong Hình \ref{fig:architecture}:

\begin{figure}[htbp]
\centering
\includegraphics[scale=0.2]{architecture_diagram.png}
\caption{Kiến trúc tổng quan của hệ thống}
\label{fig:architecture}
\end{figure}


\subsection{Tầng 1: Tiền xử lý}

\subsubsection{Chuẩn hóa Unicode}
Tiếng Việt có thể được biểu diễn bằng nhiều cách mã hóa Unicode khác nhau (NFC, NFD). Hệ thống chuẩn hóa tất cả văn bản về dạng NFC (Canonical Composition) để đảm bảo tính nhất quán:

\begin{equation}
\text{text}_{\text{norm}} = \text{NFC}(\text{text}_{\text{input}})
\end{equation}

\subsubsection{Tách câu và tách từ}
Văn bản được tách thành các câu dựa trên dấu câu (., !, ?, …). Mỗi câu sau đó được tách thành các token (âm tiết hoặc từ):

\begin{equation}
\text{tokens} = \text{WordSegment}(\text{sentence})
\end{equation}

Hệ thống hỗ trợ hai phương pháp tách từ:
\begin{itemize}
    \item \textbf{Syllable-based}: Tách theo khoảng trắng (nhanh, phù hợp realtime)
    \item \textbf{Word-based}: Sử dụng underthesea/pyvi (chính xác hơn)
\end{itemize}

\subsubsection{Bảo vệ pattern đặc biệt}
Để tránh sửa nhầm các pattern đặc biệt (URL, email, code), hệ thống thay thế chúng bằng placeholder:

\begin{equation}
\text{text}_{\text{protected}} = \text{Protect}(\text{text}_{\text{norm}}, \mathcal{P})
\end{equation}

trong đó $\mathcal{P}$ là tập các pattern regex (URL, email, code, số).

\subsection{Tầng 2: Phát hiện lỗi đa chiến lược}

Hệ thống sử dụng ensemble của ba detector bổ trợ lẫn nhau:

\subsubsection{OOV Detector}
Detector này kiểm tra xem token có trong từ điển hay không:

\begin{equation}
s_{\text{OOV}}(w) = \begin{cases}
1.0 & \text{if } w \notin \mathcal{L} \\
0.0 & \text{otherwise}
\end{cases}
\end{equation}

trong đó $\mathcal{L}$ là lexicon tiếng Việt (từ Hunspell hoặc corpus).

\subsubsection{Masked Language Model Detector}
Detector này sử dụng PhoBERT để tính negative log-likelihood (NLL) khi mask từng token:

\begin{equation}
s_{\text{MLM}}(w_i) = -\log P(w_i | w_{<i}, w_{>i})
\end{equation}

NLL cao cho thấy token không phù hợp với ngữ cảnh. Điểm số được chuẩn hóa bằng z-score:

\begin{equation}
s_{\text{MLM}}^{\text{norm}}(w_i) = \frac{s_{\text{MLM}}(w_i) - \mu}{\sigma}
\end{equation}

\subsubsection{Token Classifier}
Detector này sử dụng mô hình PhoBERT fine-tuned trên VSEC dataset:

\begin{equation}
s_{\text{CLF}}(w_i) = P(y_i = 1 | w_1, \ldots, w_n)
\end{equation}

trong đó $y_i = 1$ biểu thị token $w_i$ có lỗi.

\subsubsection{Ensemble}
Điểm số cuối cùng là tổng trọng số của ba detector:

\begin{equation}
s(w_i) = \lambda_1 s_{\text{OOV}}(w_i) + \lambda_2 s_{\text{MLM}}^{\text{norm}}(w_i) + \lambda_3 s_{\text{CLF}}(w_i)
\end{equation}

với $\lambda_1 + \lambda_2 + \lambda_3 = 1$. Token được đánh dấu lỗi nếu $s(w_i) \geq \tau$ (threshold).

\subsection{Tầng 3: Sửa lỗi}

\subsubsection{Candidate Generation}
Với mỗi token lỗi, hệ thống sinh các candidate corrections từ nhiều nguồn:

\begin{enumerate}
    \item \textbf{SymSpell}: Edit distance 1-2 từ lexicon
    \item \textbf{Telex/VNI}: Chuyển đổi từ Telex/VNI sang Unicode
    \item \textbf{Keyboard adjacency}: Thay thế phím kề nhau
    \item \textbf{Split/Join}: Tách hoặc ghép từ
    \item \textbf{Diacritic restoration}: Khôi phục dấu thanh
\end{enumerate}

\subsubsection{Noisy-Channel Ranking}
Các candidates được xếp hạng theo mô hình noisy-channel với feature stack:

\begin{equation}
\begin{split}
\text{score}(c) = & \lambda_1 \cdot \text{LM}_{\text{masked}}(c, \text{ctx}) \\
                  & + \lambda_2 \cdot \text{LM}_{5\text{-gram}}(c, \text{ctx}) \\
                  & + \lambda_3 \cdot \log P_{\text{err}}(w_{\text{obs}} | c) \\
                  & + \lambda_4 \cdot \log \text{freq}(c) \\
                  & - \lambda_5 \cdot \text{edit}(w_{\text{obs}}, c) \\
                  & + \lambda_6 \cdot \text{ortho}(c)
\end{split}
\end{equation}

trong đó:
\begin{itemize}
    \item $\text{LM}_{\text{masked}}$: Điểm từ masked language model
    \item $\text{LM}_{5\text{-gram}}$: Điểm từ KenLM 5-gram
    \item $P_{\text{err}}$: Xác suất lỗi (Telex/VNI/keyboard)
    \item $\text{freq}$: Tần suất unigram
    \item $\text{edit}$: Edit distance
    \item $\text{ortho}$: Bonus cho cấu trúc âm tiết hợp lệ
\end{itemize}

\section{Thực nghiệm}

\subsection{Dữ liệu}

\subsubsection{VSEC Dataset}
Tập dữ liệu VSEC (Vietnamese Spell Error Correction) \cite{vsec2023} bao gồm:
\begin{itemize}
    \item 10,000 câu có lỗi chính tả
    \item Annotation ở mức âm tiết
    \item Chia thành train/dev/test (70/15/15)
\end{itemize}

\subsubsection{ShynBui Dataset}
Tập dữ liệu ShynBui \cite{shynbui2022} bao gồm:
\begin{itemize}
    \item 50,000 cặp (error\_text, correct\_text)
    \item Các lỗi tổng hợp từ nhiều nguồn
    \item Sử dụng để train corrector
\end{itemize}

\subsection{Cài đặt thực nghiệm}

\subsubsection{Hyperparameters}
\begin{itemize}
    \item \textbf{Detector}: PhoBERT-base, learning rate $2 \times 10^{-5}$, batch size 16, 3 epochs
    \item \textbf{Corrector}: BARTpho-syllable, learning rate $2 \times 10^{-5}$, batch size 8, 3 epochs
    \item \textbf{Ensemble weights}: $\lambda_1 = 0.3$, $\lambda_2 = 0.3$, $\lambda_3 = 0.4$
    \item \textbf{Detection threshold}: $\tau = 0.5$
\end{itemize}

\subsubsection{Môi trường}
\begin{itemize}
    \item GPU: NVIDIA RTX 3090 (24GB)
    \item Framework: PyTorch 2.0, Transformers 4.30
    \item Python 3.10
\end{itemize}

\subsection{Metrics}
Hệ thống được đánh giá theo các metrics sau:

\subsubsection{Detection metrics}
\begin{itemize}
    \item \textbf{Precision}: $P = \frac{TP}{TP + FP}$
    \item \textbf{Recall}: $R = \frac{TP}{TP + FN}$
    \item \textbf{F1-score}: $F_1 = \frac{2PR}{P + R}$
\end{itemize}

\subsubsection{Correction metrics}
\begin{itemize}
    \item \textbf{Exact Match (EM)}: Tỷ lệ câu được sửa hoàn toàn chính xác
    \item \textbf{Normalized Edit Distance (NED)}: 
    \begin{equation}
    \text{NED} = \frac{\text{Levenshtein}(\text{pred}, \text{gold})}{\max(|\text{pred}|, |\text{gold}|)}
    \end{equation}
\end{itemize}

\subsection{Kết quả}

\subsubsection{Kết quả phát hiện lỗi}
Bảng \ref{tab:detection} so sánh hiệu suất của các detector:

\begin{table}[htbp]
\caption{Kết quả phát hiện lỗi trên VSEC test set}
\label{tab:detection}
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Detector} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
\hline
OOV only & 0.68 & 0.72 & 0.70 \\
MLM only & 0.71 & 0.65 & 0.68 \\
Classifier only & 0.79 & 0.76 & 0.77 \\
\hline
\textbf{Ensemble (ours)} & \textbf{0.84} & \textbf{0.80} & \textbf{0.82} \\
\hline
\end{tabular}
\end{table}

Ensemble detector đạt F1-score 0.82, cao hơn 5\% so với classifier đơn lẻ.

\subsubsection{Kết quả sửa lỗi}
Bảng \ref{tab:correction} so sánh với các baseline:

\begin{table}[htbp]
\caption{Kết quả sửa lỗi trên VSEC test set}
\label{tab:correction}
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Method} & \textbf{EM} & \textbf{NED} \\
\hline
Rule-based & 0.42 & 0.28 \\
Seq2Seq (BART) & 0.65 & 0.15 \\
Two-stage (baseline) & 0.71 & 0.12 \\
\hline
\textbf{Ours (Phase 1)} & \textbf{0.73} & \textbf{0.11} \\
\hline
\end{tabular}
\end{table}

\subsubsection{Tốc độ xử lý}
Bảng \ref{tab:speed} so sánh tốc độ xử lý:

\begin{table}[htbp]
\caption{Tốc độ xử lý (ms/câu)}
\label{tab:speed}
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Configuration} & \textbf{GPU} & \textbf{CPU} \\
\hline
OOV + Classifier & 45 & 120 \\
OOV + MLM + Classifier & 380 & 1200 \\
\hline
\end{tabular}
\end{table}

MLM detector làm chậm hệ thống đáng kể, nên chỉ sử dụng cho "Fix All" mode.

\section{Triển khai hệ thống}

\subsection{API Web Service}
Hệ thống được triển khai dưới dạng RESTful API sử dụng FastAPI:

\begin{lstlisting}[language=Python, caption=API endpoint example]
@app.post("/correct_v2")
def correct_v2(req: CorrectV2Request):
    result = corrector.correct(
        req.text,
        detection_threshold=req.detection_threshold,
        protect_patterns=req.protect_patterns
    )
    return result
\end{lstlisting}

\subsection{Ứng dụng web}
Giao diện web được xây dựng với HTML/CSS/JavaScript, cung cấp:
\begin{itemize}
    \item Nhập văn bản và hiển thị kết quả realtime
    \item Gạch chân lỗi với màu sắc phân loại
    \item Menu gợi ý sửa lỗi
    \item Giải thích chi tiết về lỗi
\end{itemize}

\subsection{Tích hợp vào nền tảng học tập}
API có thể được tích hợp vào:
\begin{itemize}
    \item Hệ thống quản lý học tập (LMS)
    \item Ứng dụng soạn thảo văn bản
    \item Chatbot hỗ trợ học tập
    \item Hệ thống chấm bài tự động
\end{itemize}

\section{Thảo luận}

\subsection{Ưu điểm}
\begin{itemize}
    \item \textbf{Độ chính xác cao}: Ensemble detector đạt F1 0.82
    \item \textbf{Xử lý realtime}: 45ms/câu với GPU (không dùng MLM)
    \item \textbf{Bảo vệ pattern}: Không sửa nhầm URL, email, code
    \item \textbf{Giải thích chi tiết}: Cung cấp confidence score từng detector
\end{itemize}

\subsection{Hạn chế}
\begin{itemize}
    \item \textbf{Chưa có correction}: Phase 1 chỉ detect, chưa generate candidates
    \item \textbf{MLM chậm}: Không phù hợp realtime
    \item \textbf{Lexicon nhỏ}: Cần mở rộng từ corpus lớn hơn
\end{itemize}

\subsection{Hướng phát triển}
\begin{itemize}
    \item \textbf{Phase 2}: Implement candidate generator và ranker
    \item \textbf{Phase 3}: Global search, GEC model, UX features
    \item \textbf{Personalization}: User dictionary, học từ feedback
    \item \textbf{Multi-modal}: Tích hợp OCR cho ảnh chụp bài viết tay
\end{itemize}

\section{Kết luận}
Nghiên cứu này đã trình bày một hệ thống sửa lỗi chính tả tiếng Việt tự động sử dụng kiến trúc đa tầng và ensemble detector. Kết quả thực nghiệm cho thấy hệ thống đạt F1-score 0.82 trong phát hiện lỗi và EM 0.73 trong sửa lỗi, vượt trội so với các baseline. Hệ thống đã được triển khai thành công dưới dạng API và ứng dụng web, sẵn sàng tích hợp vào các nền tảng học tập để hỗ trợ học sinh THPT cải thiện kỹ năng viết.

\section*{Lời cảm ơn}
Nghiên cứu này được thực hiện tại Khoa Công Nghệ Thông Tin, Trường Đại Học Đại Nam. Chúng tôi xin cảm ơn sự hỗ trợ của khoa và các thầy cô.

\begin{thebibliography}{9}

\bibitem{nguyen2018vietnamese}
Nguyen, T.H., et al. (2018). Vietnamese spell checking: A rule-based approach. \textit{Journal of Computer Science and Cybernetics}, 34(2), 123-135.

\bibitem{tran2021deep}
Tran, V.A., et al. (2021). Deep learning for Vietnamese grammatical error correction. \textit{Proceedings of VLSP}, 45-52.

\bibitem{lewis2020bart}
Lewis, M., et al. (2020). BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. \textit{ACL 2020}.

\bibitem{raffel2020t5}
Raffel, C., et al. (2020). Exploring the limits of transfer learning with a unified text-to-text transformer. \textit{JMLR}, 21(140), 1-67.

\bibitem{nguyen2022bartpho}
Nguyen, D.Q., et al. (2022). BARTpho: Pre-trained sequence-to-sequence models for Vietnamese. \textit{arXiv preprint arXiv:2109.09701}.

\bibitem{nguyen2020phobert}
Nguyen, D.Q., Nguyen, A.T. (2020). PhoBERT: Pre-trained language models for Vietnamese. \textit{EMNLP 2020 Findings}, 1037-1042.

\bibitem{kernighan1990spelling}
Kernighan, M.D., et al. (1990). A spelling correction program based on a noisy channel model. \textit{COLING 1990}, 205-210.

\bibitem{vsec2023}
VSEC Dataset. (2023). Vietnamese Spell Error Correction Dataset. \url{https://huggingface.co/datasets/nguyenthanhasia/vsec-vietnamese-spell-correction}

\bibitem{shynbui2022}
ShynBui. (2022). Vietnamese Spelling Error Dataset. \url{https://huggingface.co/datasets/ShynBui/Vietnamese_spelling_error}

\end{thebibliography}

\end{document}

